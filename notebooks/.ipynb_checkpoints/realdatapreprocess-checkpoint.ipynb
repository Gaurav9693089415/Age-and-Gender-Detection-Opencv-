{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "070158f1-e350-4f7a-b747-6d8dd78bfaf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m58889256/58889256\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 1us/step\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load a pre-trained VGGFace model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "# Add custom layers for gender and age prediction\n",
    "x = base_model.output\n",
    "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "gender_output = Dense(2, activation='softmax', name='gender')(x)\n",
    "age_output = Dense(1, activation='linear', name='age')(x)\n",
    "\n",
    "# Create final model\n",
    "model = Model(inputs=base_model.input, outputs=[gender_output, age_output])\n",
    "\n",
    "# Load pre-trained weights for age and gender prediction (you'll need to train or download a pre-trained model for this)\n",
    "# You can use models from resources like Kaggle or other repositories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35d6292-aea5-4a87-9fe3-eeecdb300a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the image\n",
    "img = cv2.imread(r\"D:\\WhatsApp Image 2025-04-29 at 09.44.21_067ba0b0.jpg\")\n",
    "\n",
    "# Resize the image to the input size expected by the model\n",
    "img = cv2.resize(img, (224, 224))  # Update this size based on your model\n",
    "\n",
    "# Normalize the image if required (common for pre-trained models)\n",
    "img = img / 255.0\n",
    "\n",
    "# Add batch dimension (assuming the model expects 4D input: batch_size, height, width, channels)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "\n",
    "# Predict using the model\n",
    "predicted_age, predicted_gender = model.predict(img)\n",
    "\n",
    "print(f'Predicted Gender: {predicted_gender[0]}')\n",
    "print(f'Predicted Age: {int(predicted_age[0])}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48918f40-e906-4581-aabc-9a71ceed7244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
